# ResNet128 深度学习训练项目

使用 Weights & Biases (wandb) 进行实验跟踪、可视化和模型管理的完整深度学习训练流程。

##  项目概述

本项目实现了一个完整的ResNet128深度学习训练流程，包含：

- **ResNet128模型架构**：基于残差连接的深度卷积神经网络
- **实验跟踪**：使用wandb记录超参数、指标和模型版本
- **可视化分析**：训练曲线、混淆矩阵等图表
- **模型管理**：自动保存最佳模型和版本控制
- **推理部署**：训练完成后的模型测试和预测

##  项目结构

```
wandb/
├── requirements.txt          # 项目依赖包
├── resnet128_train.py       # 主要训练脚本
├── model_inference.py       # 模型推理脚本
├── README.md               # 项目说明文档
├── models/                 # 模型保存目录（自动创建）
│   ├── best_model.pth     # 最佳验证准确率模型
│   └── final_model.pth    # 最终训练模型
└── data/                  # 数据集目录（自动下载）
```

##  快速开始

### 1. 环境准备

首先安装所需的依赖包：

```bash
pip install -r requirements.txt
```

### 2. 配置Wandb

在开始训练之前，您需要：

1. 注册 [Weights & Biases](https://wandb.ai/) 账户
2. 获取API密钥
3. 在终端中登录：

```bash
wandb login
```

### 3. 开始训练

运行训练脚本：

```bash
python resnet128_train.py
```

训练过程将自动：
- 下载CIFAR-10数据集
- 创建ResNet128模型
- 开始训练循环
- 记录所有指标到wandb
- 保存最佳模型

### 4. 模型推理

训练完成后，运行推理脚本：

```bash
python model_inference.py
```

## 📊 功能特性

### 1. 实验跟踪和版本控制

- **超参数管理**：学习率、批次大小、优化器等
- **指标记录**：训练/验证损失、准确率、学习率变化
- **模型版本**：自动保存最佳模型和最终模型
- **实验对比**：不同超参数组合的效果比较

### 2. 可视化和分析

- **实时监控**：训练过程中的指标变化
- **训练曲线**：损失和准确率趋势图
- **混淆矩阵**：分类性能详细分析
- **概率分布**：预测结果的置信度分析

### 3. 模型登记和部署

- **模型保存**：本地和云端双重备份
- **权重管理**：模型状态、优化器状态等
- **元数据记录**：训练配置、性能指标等
- **版本追踪**：每次实验的唯一标识

## 🔧 配置说明

### 主要超参数

```python
config = {
    # 模型参数
    "model": "ResNet128",
    "num_classes": 10,
    "learning_rate": 0.001,
    "batch_size": 32,
    "epochs": 100,
    
    # 优化器设置
    "optimizer": "Adam",
    "scheduler": "StepLR",
    "step_size": 30,
    "gamma": 0.1,
    
    # 数据增强
    "data_augmentation": True,
    "random_crop": 32,
    "random_horizontal_flip": 0.5,
    
    # 训练控制
    "early_stopping_patience": 10,
    "save_best_model": True
}
```

### 数据预处理

- **标准化**：使用CIFAR-10数据集的均值和标准差
- **数据增强**：随机裁剪、水平翻转
- **批次大小**：32（可根据GPU内存调整）

## 📈 训练流程详解

### 阶段1：初始化
1. 设置wandb实验配置
2. 检测计算设备（GPU/CPU）
3. 创建ResNet128模型实例
4. 初始化优化器和学习率调度器

### 阶段2：数据准备
1. 下载CIFAR-10数据集
2. 应用数据增强和标准化
3. 创建训练和验证数据加载器

### 阶段3：训练循环
1. **前向传播**：计算模型输出和损失
2. **反向传播**：计算梯度并更新权重
3. **验证评估**：在验证集上评估性能
4. **指标记录**：将结果上传到wandb
5. **模型保存**：保存最佳性能模型

### 阶段4：结果分析
1. 生成训练曲线图
2. 计算最终性能指标
3. 上传模型和图表到wandb

##  模型架构

### ResNet128结构

```
输入图像 (3×32×32)
    ↓
初始卷积层 (64通道)
    ↓
残差层组1 (64通道, 2个块)
    ↓
残差层组2 (128通道, 2个块)
    ↓
残差层组3 (256通道, 2个块)
    ↓
残差层组4 (512通道, 2个块)
    ↓
全局平均池化
    ↓
全连接分类器 (10类别)
```

### 残差块设计

每个残差块包含：
- 两个3×3卷积层
- 批归一化
- ReLU激活函数
- 跳跃连接

##  性能指标

训练过程中会记录以下指标：

- **训练损失**：每个epoch的平均训练损失
- **训练准确率**：训练集上的分类准确率
- **验证损失**：验证集上的平均损失
- **验证准确率**：验证集上的分类准确率
- **学习率**：当前学习率值

##  监控和调试

### 实时监控

- 使用wandb仪表板实时查看训练进度
- 监控损失和准确率变化趋势
- 及时发现过拟合或欠拟合问题

### 早停机制

- 连续10个epoch验证准确率未提升时自动停止
- 防止过拟合，节省训练时间
- 自动保存最佳模型

### 错误处理

- 完整的异常处理机制
- 训练中断时自动保存进度
- 详细的错误日志记录

##  高级功能

### 超参数调优

可以通过修改配置进行超参数实验：

```python
# 尝试不同的学习率
config.learning_rate = 0.0001  # 更小的学习率
config.learning_rate = 0.01    # 更大的学习率

# 调整批次大小
config.batch_size = 16         # 更小的批次
config.batch_size = 64         # 更大的批次
```

### 模型比较

在wandb中可以：
- 比较不同超参数组合的效果
- 查看模型架构的差异
- 分析训练稳定性

### 团队协作

- 共享实验结果
- 代码版本控制
- 模型权重共享

##  故障排除

### 常见问题

1. **CUDA内存不足**
   - 减小批次大小
   - 使用CPU训练
   - 减少模型复杂度

2. **训练不收敛**
   - 检查学习率设置
   - 调整优化器参数
   - 检查数据预处理

3. **过拟合**
   - 增加数据增强
   - 使用早停机制
   - 添加正则化

### 性能优化

- 使用混合精度训练
- 多GPU并行训练
- 数据加载优化

##  学习资源

- [PyTorch官方文档](https://pytorch.org/docs/)
- [Wandb使用指南](https://docs.wandb.ai/)
- [ResNet论文](https://arxiv.org/abs/1512.03385)
- [CIFAR-10数据集](https://www.cs.toronto.edu/~kriz/cifar.html)

##  贡献指南

欢迎提交问题和改进建议！

---

**注意**：首次运行时会自动下载CIFAR-10数据集（约170MB），请确保网络连接正常。 
