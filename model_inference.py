"""
ResNet128 æ¨¡å‹æ¨ç†è„šæœ¬
ç”¨äºåŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å¹¶è¿›è¡Œé¢„æµ‹

"""

import torch
import torch.nn as nn
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
import wandb
import os
from resnet128_train import ResNet128

# CIFAR-10ç±»åˆ«åç§°
CIFAR10_CLASSES = [
    'airplane', 'automobile', 'bird', 'cat', 'deer',
    'dog', 'frog', 'horse', 'ship', 'truck'
]

def load_trained_model(model_path, num_classes=10, device='cpu'):
    """
    åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
    
    å‚æ•°:
        model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        num_classes: ç±»åˆ«æ•°é‡
        device: è®¡ç®—è®¾å¤‡
    
    è¿”å›:
        åŠ è½½äº†æƒé‡çš„æ¨¡å‹
    """
    print(f"ğŸ“¥ æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    
    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    model = ResNet128(num_classes=num_classes).to(device)
    
    # åŠ è½½æ¨¡å‹æƒé‡
    checkpoint = torch.load(model_path, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    
    # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    model.eval()
    
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    print(f"   - è®­ç»ƒè½®æ¬¡: {checkpoint.get('epoch', 'N/A')}")
    print(f"   - æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {checkpoint.get('best_val_acc', 'N/A'):.2f}%")
    
    return model, checkpoint

def preprocess_image(image_path, target_size=32):
    """
    é¢„å¤„ç†å›¾åƒç”¨äºæ¨¡å‹è¾“å…¥
    
    å‚æ•°:
        image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
        target_size: ç›®æ ‡å°ºå¯¸
    
    è¿”å›:
        é¢„å¤„ç†åçš„å›¾åƒå¼ é‡
    """
    # åŠ è½½å›¾åƒ
    image = Image.open(image_path).convert('RGB')
    
    # è°ƒæ•´å›¾åƒå¤§å°
    image = image.resize((target_size, target_size))
    
    # è½¬æ¢ä¸ºå¼ é‡å¹¶æ ‡å‡†åŒ–
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(
            mean=[0.4914, 0.4822, 0.4465],
            std=[0.2023, 0.1994, 0.2010]
        )
    ])
    
    # æ·»åŠ æ‰¹æ¬¡ç»´åº¦
    image_tensor = transform(image).unsqueeze(0)
    
    return image_tensor, image

def predict_single_image(model, image_tensor, device):
    """
    å¯¹å•å¼ å›¾åƒè¿›è¡Œé¢„æµ‹
    
    å‚æ•°:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        image_tensor: é¢„å¤„ç†åçš„å›¾åƒå¼ é‡
        device: è®¡ç®—è®¾å¤‡
    
    è¿”å›:
        é¢„æµ‹ç»“æœå’Œæ¦‚ç‡
    """
    with torch.no_grad():
        # å°†å›¾åƒç§»åˆ°è®¾å¤‡ä¸Š
        image_tensor = image_tensor.to(device)
        
        # å‰å‘ä¼ æ’­
        outputs = model(image_tensor)
        
        # è·å–é¢„æµ‹ç±»åˆ«å’Œæ¦‚ç‡
        probabilities = torch.softmax(outputs, dim=1)
        predicted_class = torch.argmax(probabilities, dim=1).item()
        confidence = probabilities[0][predicted_class].item()
        
        # è·å–æ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡
        all_probabilities = probabilities[0].cpu().numpy()
        
        return predicted_class, confidence, all_probabilities

def visualize_prediction(image, predicted_class, confidence, all_probabilities, save_path=None):
    """
    å¯è§†åŒ–é¢„æµ‹ç»“æœ
    
    å‚æ•°:
        image: åŸå§‹å›¾åƒ
        predicted_class: é¢„æµ‹çš„ç±»åˆ«
        confidence: é¢„æµ‹ç½®ä¿¡åº¦
        all_probabilities: æ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡
        save_path: ä¿å­˜è·¯å¾„
    """
    # åˆ›å»ºå›¾è¡¨
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # æ˜¾ç¤ºå›¾åƒ
    ax1.imshow(image)
    ax1.set_title(f'é¢„æµ‹ç»“æœ: {CIFAR10_CLASSES[predicted_class]} (ç½®ä¿¡åº¦: {confidence:.2%})')
    ax1.axis('off')
    
    # æ˜¾ç¤ºæ¦‚ç‡åˆ†å¸ƒ
    bars = ax2.bar(range(len(CIFAR10_CLASSES)), all_probabilities)
    ax2.set_xlabel('ç±»åˆ«')
    ax2.set_ylabel('æ¦‚ç‡')
    ax2.set_title('å„ç±»åˆ«é¢„æµ‹æ¦‚ç‡')
    ax2.set_xticks(range(len(CIFAR10_CLASSES)))
    ax2.set_xticklabels(CIFAR10_CLASSES, rotation=45, ha='right')
    
    # é«˜äº®é¢„æµ‹çš„ç±»åˆ«
    bars[predicted_class].set_color('red')
    
    # æ·»åŠ æ¦‚ç‡å€¼æ ‡ç­¾
    for i, prob in enumerate(all_probabilities):
        ax2.text(i, prob + 0.01, f'{prob:.3f}', ha='center', va='bottom')
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š é¢„æµ‹ç»“æœå›¾å·²ä¿å­˜: {save_path}")
    
    plt.show()

def batch_predict(model, data_loader, device):
    """
    æ‰¹é‡é¢„æµ‹
    
    å‚æ•°:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        data_loader: æ•°æ®åŠ è½½å™¨
        device: è®¡ç®—è®¾å¤‡
    
    è¿”å›:
        é¢„æµ‹ç»“æœå’ŒçœŸå®æ ‡ç­¾
    """
    model.eval()
    all_predictions = []
    all_labels = []
    all_probabilities = []
    
    print("ğŸ” æ­£åœ¨è¿›è¡Œæ‰¹é‡é¢„æµ‹...")
    
    with torch.no_grad():
        for batch_idx, (data, target) in enumerate(data_loader):
            data, target = data.to(device), target.to(device)
            
            # å‰å‘ä¼ æ’­
            outputs = model(data)
            probabilities = torch.softmax(outputs, dim=1)
            predicted = torch.argmax(probabilities, dim=1)
            
            # æ”¶é›†ç»“æœ
            all_predictions.extend(predicted.cpu().numpy())
            all_labels.extend(target.cpu().numpy())
            all_probabilities.extend(probabilities.cpu().numpy())
            
            if (batch_idx + 1) % 10 == 0:
                print(f"   å·²å¤„ç† {batch_idx + 1} ä¸ªæ‰¹æ¬¡")
    
    print(f"âœ… æ‰¹é‡é¢„æµ‹å®Œæˆï¼Œå…±å¤„ç† {len(all_predictions)} ä¸ªæ ·æœ¬")
    
    return np.array(all_predictions), np.array(all_labels), np.array(all_probabilities)

def calculate_metrics(predictions, labels):
    """
    è®¡ç®—é¢„æµ‹æŒ‡æ ‡
    
    å‚æ•°:
        predictions: é¢„æµ‹ç»“æœ
        labels: çœŸå®æ ‡ç­¾
    
    è¿”å›:
        å„ç§è¯„ä¼°æŒ‡æ ‡
    """
    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
    
    # è®¡ç®—å‡†ç¡®ç‡
    accuracy = accuracy_score(labels, predictions)
    
    # åˆ†ç±»æŠ¥å‘Š
    report = classification_report(labels, predictions, 
                                 target_names=CIFAR10_CLASSES, 
                                 output_dict=True)
    
    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(labels, predictions)
    
    return {
        'accuracy': accuracy,
        'classification_report': report,
        'confusion_matrix': cm
    }

def log_to_wandb(metrics, predictions, labels, probabilities, model_path):
    """
    å°†é¢„æµ‹ç»“æœè®°å½•åˆ°wandb
    
    å‚æ•°:
        metrics: è¯„ä¼°æŒ‡æ ‡
        predictions: é¢„æµ‹ç»“æœ
        labels: çœŸå®æ ‡ç­¾
        probabilities: é¢„æµ‹æ¦‚ç‡
        model_path: æ¨¡å‹è·¯å¾„
    """
    # è®°å½•æŒ‡æ ‡
    wandb.log({
        "test_accuracy": metrics['accuracy'],
        "test_precision_macro": metrics['classification_report']['macro avg']['precision'],
        "test_recall_macro": metrics['classification_report']['macro avg']['recall'],
        "test_f1_macro": metrics['classification_report']['macro avg']['f1-score']
    })
    
    # åˆ›å»ºæ··æ·†çŸ©é˜µå›¾
    fig, ax = plt.subplots(figsize=(10, 8))
    im = ax.imshow(metrics['confusion_matrix'], cmap='Blues')
    
    # æ·»åŠ æ ‡ç­¾
    ax.set_xticks(range(len(CIFAR10_CLASSES)))
    ax.set_yticks(range(len(CIFAR10_CLASSES)))
    ax.set_xticklabels(CIFAR10_CLASSES, rotation=45, ha='right')
    ax.set_yticklabels(CIFAR10_CLASSES)
    ax.set_xlabel('é¢„æµ‹ç±»åˆ«')
    ax.set_ylabel('çœŸå®ç±»åˆ«')
    ax.set_title('æ··æ·†çŸ©é˜µ')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i in range(len(CIFAR10_CLASSES)):
        for j in range(len(CIFAR10_CLASSES)):
            text = ax.text(j, i, metrics['confusion_matrix'][i, j],
                          ha="center", va="center", color="black")
    
    plt.tight_layout()
    
    # ä¸Šä¼ åˆ°wandb
    wandb.log({"confusion_matrix": wandb.Image(fig)})
    plt.close()
    
    # è®°å½•æ¨¡å‹æ–‡ä»¶
    model_artifact = wandb.Artifact(
        name=f"inference-model-{wandb.run.id}",
        type="model",
        description="ç”¨äºæ¨ç†çš„ResNet128æ¨¡å‹"
    )
    model_artifact.add_file(model_path)
    wandb.log_artifact(model_artifact)
    
    print("âœ… é¢„æµ‹ç»“æœå·²è®°å½•åˆ°wandb")

def main():
    """
    ä¸»å‡½æ•°
    """
    print("ğŸš€ å¼€å§‹ResNet128æ¨¡å‹æ¨ç†...")
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æ¨¡å‹è·¯å¾„
    model_path = "./models/best_model.pth"
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print("è¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬æˆ–æ£€æŸ¥æ¨¡å‹è·¯å¾„")
        return
    
    # åˆå§‹åŒ–wandbï¼ˆç”¨äºè®°å½•æ¨ç†ç»“æœï¼‰
    wandb.init(
        project="resnet128-inference",
        name=f"inference-{os.path.basename(model_path)}",
        config={
            "model_path": model_path,
            "device": str(device),
            "num_classes": 10
        }
    )
    
    try:
        # åŠ è½½æ¨¡å‹
        model, checkpoint = load_trained_model(model_path, device=device)
        
        # ç¤ºä¾‹ï¼šå•å¼ å›¾åƒé¢„æµ‹
        print("\nğŸ“¸ å•å¼ å›¾åƒé¢„æµ‹ç¤ºä¾‹:")
        print("æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨éšæœºç”Ÿæˆçš„å›¾åƒä½œä¸ºç¤ºä¾‹")
        print("åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œæ‚¨å¯ä»¥æ›¿æ¢ä¸ºçœŸå®çš„å›¾åƒæ–‡ä»¶è·¯å¾„")
        
        # åˆ›å»ºéšæœºå›¾åƒè¿›è¡Œæ¼”ç¤ºï¼ˆå®é™…ä½¿ç”¨ä¸­æ›¿æ¢ä¸ºçœŸå®å›¾åƒï¼‰
        random_image = np.random.randint(0, 255, (32, 32, 3), dtype=np.uint8)
        random_image = Image.fromarray(random_image)
        
        # é¢„å¤„ç†å›¾åƒ
        image_tensor, _ = preprocess_image_from_pil(random_image)
        
        # è¿›è¡Œé¢„æµ‹
        predicted_class, confidence, all_probabilities = predict_single_image(
            model, image_tensor, device
        )
        
        print(f"é¢„æµ‹ç±»åˆ«: {CIFAR10_CLASSES[predicted_class]}")
        print(f"ç½®ä¿¡åº¦: {confidence:.2%}")
        
        # å¯è§†åŒ–ç»“æœ
        visualize_prediction(
            random_image, 
            predicted_class, 
            confidence, 
            all_probabilities,
            save_path="prediction_result.png"
        )
        
        # æ‰¹é‡é¢„æµ‹ï¼ˆå¦‚æœæœ‰éªŒè¯æ•°æ®ï¼‰
        print("\nğŸ“Š æ‰¹é‡é¢„æµ‹:")
        print("å¦‚æœæ‚¨æœ‰éªŒè¯æ•°æ®é›†ï¼Œå¯ä»¥å–æ¶ˆæ³¨é‡Šä»¥ä¸‹ä»£ç è¿›è¡Œæ‰¹é‡é¢„æµ‹")
        
        # ç¤ºä¾‹ä»£ç ï¼ˆéœ€è¦å–æ¶ˆæ³¨é‡Šå¹¶ä¿®æ”¹ï¼‰ï¼š
        """
        from torchvision.datasets import CIFAR10
        from torch.utils.data import DataLoader
        
        # åŠ è½½éªŒè¯æ•°æ®
        val_dataset = CIFAR10(root='./data', train=False, download=True,
                             transform=transforms.Compose([
                                 transforms.ToTensor(),
                                 transforms.Normalize([0.4914, 0.4822, 0.4465],
                                                    [0.2023, 0.1994, 0.2010])
                             ]))
        
        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
        
        # æ‰¹é‡é¢„æµ‹
        predictions, labels, probabilities = batch_predict(model, val_loader, device)
        
        # è®¡ç®—æŒ‡æ ‡
        metrics = calculate_metrics(predictions, labels)
        
        print(f"æµ‹è¯•å‡†ç¡®ç‡: {metrics['accuracy']:.4f}")
        
        # è®°å½•åˆ°wandb
        log_to_wandb(metrics, predictions, labels, probabilities, model_path)
        """
        
        print("\nâœ… æ¨ç†å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æ¨ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        raise e
    
    finally:
        # å®Œæˆwandbè¿è¡Œ
        wandb.finish()

def preprocess_image_from_pil(image, target_size=32):
    """
    ä»PILå›¾åƒé¢„å¤„ç†ï¼ˆç”¨äºæ¼”ç¤ºï¼‰
    """
    # è°ƒæ•´å›¾åƒå¤§å°
    image = image.resize((target_size, target_size))
    
    # è½¬æ¢ä¸ºå¼ é‡å¹¶æ ‡å‡†åŒ–
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(
            mean=[0.4914, 0.4822, 0.4465],
            std=[0.2023, 0.1994, 0.2010]
        )
    ])
    
    # æ·»åŠ æ‰¹æ¬¡ç»´åº¦
    image_tensor = transform(image).unsqueeze(0)
    
    return image_tensor, image

if __name__ == "__main__":
    main() 